{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator, LogLocator\n",
    "\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runs(\n",
    "        runs, metrics=METRICS, warmstart_ckpt=None, plot_warmstart=False, plot_warmstart_horizontal_line=False, n_cols=4, unify_legend=True, legend_n_col=None, unit_figsize=None, log_x_scale=False, log_y_scale=False, \n",
    "        use_token_measures=True, plot_line_kwargs=None, run_labels_map=None, display_result=False,\n",
    "        vertical_lines=None, load_metric_kwargs=None, top_runs=None, plot_group_legend=False, group_legend_num_items_row=2,\n",
    "    ):\n",
    "\n",
    "    additional_plot_types = [\"envelope\", \"smoothed\"]\n",
    "    if plot_line_kwargs is None:\n",
    "        plot_line_kwargs = {\n",
    "            \"average\": {  # average of all trials\n",
    "                \"errorbar\": \"se\",\n",
    "            },\n",
    "            # \"envelope\": {  # envelope of all trials\n",
    "            #     \"errorbar\": \"se\",\n",
    "            # },\n",
    "            # \"smoothed\": {  # smoothed line of all trials\n",
    "            #     \"errorbar\": \"se\",\n",
    "            # },\n",
    "        }\n",
    "    \n",
    "    # gather all metrics from all runs at all steps\n",
    "    load_runs = runs.copy()\n",
    "    if warmstart_ckpt is not None and plot_warmstart:\n",
    "        load_runs[WARMSTART_NAME] = warmstart_ckpt[\"path\"]\n",
    "        potential_paths = [warmstart_ckpt[\"path\"], warmstart_ckpt[\"path\"]+\"_trial_0\"]\n",
    "        \n",
    "        warmstart_path = None\n",
    "        for path in potential_paths:\n",
    "            if os.path.exists(os.path.join(BASE_EXP_DIR, path, \"config.yaml\")):\n",
    "                warmstart_path = os.path.join(BASE_EXP_DIR, path)\n",
    "                break\n",
    "        \n",
    "        if warmstart_path is None:\n",
    "            raise ValueError(f\"Warmstart path not found for {warmstart_ckpt['path']}\")\n",
    "            \n",
    "        with open(os.path.join(warmstart_path, \"config.yaml\"), \"r\") as f:\n",
    "            warmstart_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "        warmstart_step = warmstart_ckpt[\"step\"]\n",
    "        loaded_warmstart_ckpt = True\n",
    "    else:\n",
    "        warmstart_step = 0\n",
    "        loaded_warmstart_ckpt = False\n",
    "    \n",
    "    if loaded_warmstart_ckpt and not plot_warmstart_horizontal_line:\n",
    "        warmstart_tokens = warmstart_config[\"data\"][\"batch_size\"] * warmstart_config[\"data\"][\"seq_len\"] * warmstart_config[\"distributed\"][\"dp_shard\"] * warmstart_step\n",
    "        warmstart_synth_raw_data_ratio = SYNTHETIC_RAW_TOKEN_RATIO_MAP[\"warmstart\"]\n",
    "    else:\n",
    "        warmstart_tokens = 0\n",
    "        warmstart_synth_raw_data_ratio = 1.0\n",
    "    \n",
    "    load_metrics = list(set(metrics))\n",
    "    if load_metric_kwargs is None:\n",
    "        load_metric_kwargs = {}\n",
    "    all_metrics = load_run_metrics(load_runs, load_metrics=load_metrics, warmstart_ckpt=warmstart_ckpt, **load_metric_kwargs)\n",
    "\n",
    "    run_order = list(runs.keys())\n",
    "    warmstart_run = None\n",
    "    if plot_warmstart:\n",
    "        if not plot_warmstart_horizontal_line:\n",
    "            # shift the steps of all runs by the step of the warmstart checkpoint\n",
    "            all_metrics.loc[(all_metrics[\"run\"] != WARMSTART_NAME) & (~all_metrics[\"run\"].str.endswith(\"(scratch)\")), \"step\"] += warmstart_step\n",
    "            all_metrics.loc[(all_metrics[\"run\"] != WARMSTART_NAME) & (~all_metrics[\"run\"].str.endswith(\"(scratch)\")), \"num_tokens\"] += warmstart_tokens\n",
    "        else:\n",
    "            warmstart_run = all_metrics[all_metrics[\"run\"] == WARMSTART_NAME]\n",
    "            # remove it from all_metrics\n",
    "            all_metrics = all_metrics[all_metrics[\"run\"] != WARMSTART_NAME]\n",
    "    \n",
    "        # run_order.insert(0, WARMSTART_NAME)\n",
    "        run_order.append(WARMSTART_NAME)\n",
    "\n",
    "    \n",
    "    # Create a grid plot, each for one metric, and different runs in one plot for comparison\n",
    "    n_metrics = len(metrics)\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "\n",
    "    # Create subplot figure\n",
    "    if unit_figsize is None:\n",
    "        unit_figsize = (6, 4)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(unit_figsize[0]*n_cols, unit_figsize[1]*n_rows))\n",
    "    if n_rows * n_cols > 1:\n",
    "        axes = axes.flatten()  # Flatten to make indexing easier\n",
    "    else:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]\n",
    "        # Use seaborn's lineplot instead of matplotlib's plot\n",
    "        if use_token_measures:\n",
    "            measure = \"num_tokens\"\n",
    "        else:\n",
    "            measure = \"step\"\n",
    "\n",
    "        x_name = measure\n",
    "        \n",
    "        plot_style_kwargs = {\n",
    "            \"linewidth\": 2.5,\n",
    "            \"alpha\": 0.6 if any(plot_line_type in plot_line_kwargs for plot_line_type in additional_plot_types) else 1.0,\n",
    "        }\n",
    "\n",
    "        # Plot horizontal lines for baseline runs at step 0\n",
    "        if run_labels_map is not None:\n",
    "            hue_orders = list(run_labels_map.keys())\n",
    "            hue_order_map = {run: hue_orders.index(run) for run in run_order}\n",
    "        else:\n",
    "            hue_order_map = {run: idx for idx, run in enumerate(run_order)}\n",
    "\n",
    "        baseline_data = all_metrics[all_metrics['step'].isna()]\n",
    "\n",
    "        if not baseline_data.empty:\n",
    "            for run in baseline_data['run'].unique():\n",
    "                run_baseline = baseline_data[baseline_data['run'] == run]\n",
    "                if not run_baseline.empty:\n",
    "                    # Calculate mean and standard error for the baseline\n",
    "                    baseline_mean = run_baseline[metric].mean()\n",
    "                    baseline_stderr = run_baseline[metric].std() / np.sqrt(len(run_baseline))\n",
    "                    \n",
    "                    # Plot the mean as a horizontal line\n",
    "                    ax.axhline(\n",
    "                        y=baseline_mean,\n",
    "                        color=sns.color_palette()[hue_order_map.get(run, 0)] if run in hue_order_map else \"gray\",\n",
    "                        linestyle='--', label=f\"{run}\",\n",
    "                        **plot_style_kwargs\n",
    "                    )\n",
    "                    \n",
    "                    # Add error band for standard error\n",
    "                    ax.axhspan(\n",
    "                        baseline_mean - baseline_stderr,\n",
    "                        baseline_mean + baseline_stderr,\n",
    "                        color=sns.color_palette()[hue_order_map.get(run, 0)] if run in hue_order_map else \"gray\",\n",
    "                        alpha=0.2\n",
    "                    )\n",
    "        \n",
    "        # Then plot the rest of the data (excluding step=0)\n",
    "        plot_data = all_metrics[all_metrics['step'].notna()]\n",
    "        hue_order_map_plot = {run: hue_order_map[run] for run in plot_data[\"run\"].unique()}\n",
    "        hue_order_map_plot = dict(sorted(hue_order_map_plot.items(), key=lambda x: x[1]))\n",
    "\n",
    "        if top_runs is None:\n",
    "            top_runs = []\n",
    "\n",
    "        plot_data_top = plot_data[plot_data[\"run\"].isin(top_runs)]\n",
    "        plot_data_bottom = plot_data[~plot_data[\"run\"].isin(top_runs)]\n",
    "\n",
    "        if \"average\" in plot_line_kwargs:\n",
    "            shared_plot_kwargs = {\n",
    "                \"x\": x_name,\n",
    "                \"y\": metric,\n",
    "                \"hue\": \"run\",\n",
    "                \"ax\": ax,\n",
    "                \"hue_order\": hue_order_map_plot,\n",
    "                \"marker\": \"o\",\n",
    "                **plot_line_kwargs[\"average\"],\n",
    "                **plot_style_kwargs,\n",
    "            }\n",
    "            # Plot bottom lines first\n",
    "            sns.lineplot(\n",
    "                data=plot_data_bottom, \n",
    "                zorder=3,  \n",
    "                **shared_plot_kwargs,\n",
    "            )\n",
    "            \n",
    "            # Plot top lines second with higher z-order\n",
    "            if not plot_data_top.empty:\n",
    "                sns.lineplot(\n",
    "                    data=plot_data_top, \n",
    "                    zorder=4,\n",
    "                    **shared_plot_kwargs,\n",
    "                )\n",
    "        \n",
    "        for plot_line_type in additional_plot_types:\n",
    "            if plot_line_type not in plot_line_kwargs:\n",
    "                continue\n",
    "\n",
    "            # Add smoothed version using rolling average\n",
    "            if \"average\" in plot_line_kwargs:\n",
    "                color_map = {line.get_label(): line.get_color() for line in ax.get_lines()}\n",
    "            else:\n",
    "                color_map = {run: sns.color_palette()[hue_order_map[run]] for run in run_order}\n",
    "        \n",
    "            extra_metrics = post_process_metrics(all_metrics, process_type=plot_line_type, metric_cols=[metric], sort_by_col=x_name)\n",
    "\n",
    "            # display(extra_metrics.head(100))\n",
    "\n",
    "            for j, run in enumerate(run_order):\n",
    "                if run in baseline_data[\"run\"].unique() or (plot_warmstart and run in warmstart_run[\"run\"].unique()):\n",
    "                    continue\n",
    "\n",
    "                run_data = extra_metrics[extra_metrics['run'] == run]\n",
    "\n",
    "                if display_result:\n",
    "                    # display the last step result\n",
    "                    last_step_data = run_data[run_data[x_name] == run_data[x_name].max()]\n",
    "                    display(last_step_data[[\"run\", \"step\", \"num_tokens\", metric]])\n",
    "\n",
    "                sns.lineplot(\n",
    "                    data=run_data, x=x_name, y=metric, \n",
    "                    ax=ax,\n",
    "                    color=color_map[run],\n",
    "                    linewidth=3,\n",
    "                    label=None if \"average\" in plot_line_kwargs else run,\n",
    "                    zorder=4 if run in top_runs else 3,\n",
    "                    **plot_line_kwargs[plot_line_type],\n",
    "                )\n",
    "\n",
    "        \n",
    "        if vertical_lines is not None:\n",
    "            assert isinstance(vertical_lines, list), \"vertical_lines must be a list\"\n",
    "            for line in vertical_lines:\n",
    "                assert isinstance(line, dict), \"vertical_lines must be a list of dictionaries\"\n",
    "                line[\"linewidth\"] = 2   \n",
    "                ax.axvline(**line)\n",
    "\n",
    "\n",
    "        if plot_warmstart and plot_warmstart_horizontal_line:\n",
    "            # ax.axhline(y=warmstart_run[warmstart_run[\"step\"] == warmstart_step][metric].iloc[0], color=sns.color_palette()[hue_order_map[WARMSTART_NAME]], linestyle=\"--\", label=f\"{WARMSTART_NAME}\", linewidth=2, zorder=2)\n",
    "            warmstart_mean = warmstart_run[warmstart_run[\"step\"] == warmstart_step][metric].mean()\n",
    "            warmstart_stderr = warmstart_run[warmstart_run[\"step\"] == warmstart_step][metric].std() / np.sqrt(len(warmstart_run))\n",
    "            ax.axhline(y=warmstart_mean, color=sns.color_palette()[hue_order_map[WARMSTART_NAME]], linestyle=\"--\", label=f\"{WARMSTART_NAME}\", linewidth=2, zorder=2)\n",
    "            ax.axhspan(warmstart_mean - warmstart_stderr, warmstart_mean + warmstart_stderr, color=sns.color_palette()[hue_order_map[WARMSTART_NAME]], alpha=0.2)\n",
    "\n",
    "\n",
    "        if run_labels_map is not None:\n",
    "            # Get all lines and their labels from the plot\n",
    "            lines = ax.get_lines()\n",
    "            for line in lines:\n",
    "                current_label = line.get_label()\n",
    "                if current_label in run_labels_map:\n",
    "                    line.set_label(run_labels_map[current_label])\n",
    "        \n",
    "        if not unify_legend:\n",
    "            # Remove existing legend if any\n",
    "            if ax.get_legend() is not None:\n",
    "                ax.get_legend().remove()\n",
    "            # Create new legend with updated labels\n",
    "            ax.legend()\n",
    "            legend = ax.get_legend()\n",
    "            for handle in legend.get_lines():\n",
    "                handle.set_alpha(1.0)\n",
    "        else:\n",
    "            if ax.get_legend() is not None:\n",
    "                ax.get_legend().remove()\n",
    "\n",
    "        ax.set_ylabel(\"Metric\")\n",
    "        ax.grid(True)\n",
    "        \n",
    "\n",
    "        if log_x_scale:\n",
    "            ax.set_xscale(\"log\", base=10)\n",
    "\n",
    "        if log_y_scale:\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.grid(True, which='both', axis='y')   # add back the grid line\n",
    "        \n",
    "        if \"nll\" in metric or \"elbo\" in metric:\n",
    "            ax.set_yscale(\"log\")\n",
    "            # disable scientific notation\n",
    "            ax.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "            ax.yaxis.set_minor_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "            ax.grid(True, which='both', axis='y')   # add back the grid line\n",
    "\n",
    "            if \"nll\" in metric:\n",
    "                ax.set_ylabel(\"NLL\")\n",
    "            elif \"elbo\" in metric:\n",
    "                ax.set_ylabel(\"ELBO w/ 4 Samples\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title(ALL_EVAL_METRIC_LABEL_MAP.get(metric, metric))\n",
    "\n",
    "        if x_name == \"num_tokens\":\n",
    "            ax.set_xlabel(\"Total Training Tokens\")\n",
    "        elif x_name == \"step\":\n",
    "            ax.set_xlabel(\"Training Steps\")\n",
    "        elif x_name == \"raw_tokens_adjusted_num_tokens\":\n",
    "            ax.set_xlabel(\"Effective Raw Tokens Seen\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown x_name: {x_name}\")\n",
    "\n",
    "\n",
    "    # Remove empty subplots if any\n",
    "    for idx in range(len(metrics), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    if unify_legend:\n",
    "        # Adjust the figure size to accommodate the legend at the top\n",
    "        plt.gcf().set_size_inches(unit_figsize[0]*n_cols, unit_figsize[1]*n_rows + 1)  # Added extra height instead of width\n",
    "        # Create unified legend at the top\n",
    "        handles, labels = axes[0].get_legend_handles_labels()\n",
    "        \n",
    "        if any(plot_line_type in plot_line_kwargs for plot_line_type in additional_plot_types):\n",
    "            new_handles = []\n",
    "            for handle in handles:\n",
    "                new_handle = plt.Line2D([], [], color=handle.get_color(), label=handle.get_label(), alpha=1.0)\n",
    "                new_handles.append(new_handle)\n",
    "        else:\n",
    "            new_handles = handles\n",
    "\n",
    "        all_num_cols = 0\n",
    "        if plot_group_legend:\n",
    "            group_handles = defaultdict(list)\n",
    "            group_labels = defaultdict(list)\n",
    "            \n",
    "            for handle, label in zip(new_handles, labels):\n",
    "                group_label, sub_label = label.split(\", \")\n",
    "                if sub_label not in group_labels[group_label]:\n",
    "                    group_handles[group_label].append(handle)\n",
    "                    group_labels[group_label].append(sub_label)\n",
    "            \n",
    "            # Create a single legend with all groups\n",
    "            all_handles = []\n",
    "            all_labels = []\n",
    "            \n",
    "            # Sort groups if needed for consistent ordering\n",
    "            sorted_groups = sorted(group_handles.keys())\n",
    "            \n",
    "            for group_label in sorted_groups:\n",
    "                # Get number of items in this group\n",
    "                group_items = list(zip(group_handles[group_label], group_labels[group_label]))\n",
    "                num_items = len(group_items)\n",
    "                \n",
    "                # Calculate how many columns this group will span\n",
    "                items_num_row = group_legend_num_items_row\n",
    "                cols_per_group = (num_items + items_num_row - 1) // items_num_row\n",
    "                all_num_cols += cols_per_group\n",
    "\n",
    "                # Padding group labels to multiple of cols_per_group\n",
    "                num_padding = cols_per_group - (num_items % cols_per_group)\n",
    "                if num_padding < cols_per_group:\n",
    "                    for _ in range(num_padding):\n",
    "                        group_items.append((plt.Line2D([], [], color='none'), \"\"))\n",
    "\n",
    "                # Padding empty items in the first row (for group label) to make it column centered\n",
    "                num_group_label_padding = (cols_per_group - 1)\n",
    "                num_group_label_padding_left = (num_group_label_padding + 1) // 2\n",
    "                num_group_label_padding_right = num_group_label_padding - num_group_label_padding_left\n",
    "\n",
    "                \n",
    "                for col_idx in range(cols_per_group):\n",
    "                    # first row (for label)\n",
    "                    if col_idx < num_group_label_padding_left or col_idx >= num_group_label_padding_left + 1:\n",
    "                        # add padding\n",
    "                        all_handles.append(plt.Line2D([], [], color='none'))\n",
    "                        all_labels.append(\"\")\n",
    "                    else:\n",
    "                        # add group label\n",
    "                        all_handles.append(plt.Line2D([], [], color='none'))\n",
    "                        all_labels.append(f\"{group_label}\")\n",
    "\n",
    "\n",
    "                    # sub rows\n",
    "                    col_items = group_items[col_idx*items_num_row: (col_idx+1)*items_num_row]\n",
    "                    for handle, label in col_items:\n",
    "                        all_handles.append(handle)\n",
    "                        all_labels.append(label)\n",
    "                \n",
    "            \n",
    "            # Calculate appropriate number of columns\n",
    "            legend = fig.legend(all_handles, all_labels, \n",
    "                      bbox_to_anchor=(0.5, 1.0), \n",
    "                      loc='lower center', \n",
    "                      ncol=all_num_cols,\n",
    "                      fontsize=SIZE_MEDIUM)\n",
    "            # Make group labels bold\n",
    "            for text in legend.get_texts():\n",
    "                if text.get_text() in group_handles.keys():\n",
    "                    text.set_weight('bold')\n",
    "        else:\n",
    "            fig.legend(new_handles, labels, bbox_to_anchor=(0.5, 1.0), loc='lower center', ncol=legend_n_col or len(run_order), fontsize=SIZE_MEDIUM)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.5)  # Adjust these values as needed\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_RUNS = {\n",
    "    \"latent_bootstrap_iter=1_mc=4\": \"train_bootstrap_fixed_data_bootstrap/train_bootstrap_fixed_data_bootstrap_setup=bootstrap_latents_iter=1_mc=4_scratch\",\n",
    "    \"latent_bootstrap_iter=2_mc=4\": \"train_bootstrap_fixed_data_bootstrap/train_bootstrap_fixed_data_bootstrap_setup=bootstrap_latents_iter=2_mc=4_scratch\",\n",
    "    \"latent_bootstrap_iter=3_mc=4\": \"train_bootstrap_fixed_data_bootstrap/train_bootstrap_fixed_data_bootstrap_setup=bootstrap_latents_iter=3_mc=4_scratch\",\n",
    "    \"latent_bootstrap_iter=4_mc=4\": \"train_bootstrap_fixed_data_bootstrap/train_bootstrap_fixed_data_bootstrap_setup=bootstrap_latents_iter=4_mc=4_scratch\",\n",
    "    \"raw_token_matched_baseline\": \"train_bootstrap_fixed_data_bootstrap/train_bootstrap_fixed_data_bootstrap_setup=raw_token_matched_scratch\",\n",
    "    \"raw_flops_matched_baseline\": \"train_bootstrap_fixed_data_bootstrap/train_bootstrap_fixed_data_bootstrap_setup=raw_flops_matched_scratch\",\n",
    "}\n",
    "\n",
    "WARMSTART_CHECKPOINT = {\n",
    "    \"path\": \"train_bootstrap_fixed_data_warmstart/train_bootstrap_fixed_data_warmstart_latent=random_opt=cosine_lr=1e-4_240m_raw\",\n",
    "    \"step\": 4069,\n",
    "}\n",
    "\n",
    "\n",
    "RUN_LABELS_MAP = {\n",
    "    \"latent_bootstrap_iter=1_mc=4\": \"Latent Bootstrap, Iteration 1\",\n",
    "    \"latent_bootstrap_iter=2_mc=4\": \"Latent Bootstrap, Iteration 2\",\n",
    "    \"latent_bootstrap_iter=3_mc=4\": \"Latent Bootstrap, Iteration 3\",\n",
    "    \"latent_bootstrap_iter=4_mc=4\": \"Latent Bootstrap, Iteration 4\",\n",
    "    \"raw_token_matched_baseline\": \"Raw Baseline, Raw-Token-Match\",\n",
    "    \"raw_flops_matched_baseline\": \"Raw Baseline, Train-FLOP-Match\",\n",
    "    \"latent_warmstart\": \"Latent Bootstrap, Iteration 0 (Warmstart)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_METRICS = [\n",
    "    # \"finemath_4plus_val.nll_per_token\",\n",
    "    \"finemath_4plus_val.elbo_4_per_token\",\n",
    "    \"hendrycks_math_cot_synthetic.exact_match\",\n",
    "]\n",
    "\n",
    "PLOT_KWARGS = {\n",
    "    \"metrics\": PLOT_METRICS,\n",
    "    \"log_x_scale\": True, \n",
    "    \"log_y_scale\": False, \n",
    "    \"legend_n_col\": 4,\n",
    "    \"plot_warmstart\": True,\n",
    "    \"plot_warmstart_horizontal_line\": True,\n",
    "    \"warmstart_ckpt\": WARMSTART_CHECKPOINT, \n",
    "    \"load_metric_kwargs\": {\n",
    "        \"load_all_trials\": True,\n",
    "    },\n",
    "    \"plot_line_kwargs\": {\n",
    "        # \"average\": {\n",
    "        #     \"errorbar\": \"se\",\n",
    "        # },\n",
    "        \"envelope\": {\n",
    "            \"errorbar\": \"se\",\n",
    "        },\n",
    "        # \"smoothed\": {\n",
    "        #     \"errorbar\": \"se\",\n",
    "        # },\n",
    "    },  \n",
    "    \"n_cols\": 2,\n",
    "    \"run_labels_map\": RUN_LABELS_MAP,\n",
    "    \"plot_group_legend\": True,\n",
    "    \"legend_n_col\": 3,\n",
    "    \"top_runs\": [\"latent_bootstrap_iter=1_mc=4\", \"latent_bootstrap_iter=2_mc=4\", \"latent_bootstrap_iter=3_mc=4\", \"raw_token_matched_baseline\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_runs = {k: v for k, v in EXP_RUNS.items()}\n",
    "_plot_kwargs = copy.deepcopy(PLOT_KWARGS)\n",
    "\n",
    "fig = plot_runs(\n",
    "    _plot_runs, \n",
    "    **_plot_kwargs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact performance curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_runs = {k: v for k, v in EXP_RUNS.items()}\n",
    "_plot_kwargs = copy.deepcopy(PLOT_KWARGS)\n",
    "\n",
    "_plot_kwargs[\"plot_line_kwargs\"] = {\n",
    "        \"average\": {\n",
    "            \"errorbar\": \"se\",\n",
    "        },\n",
    "        # \"envelope\": {\n",
    "        #     \"errorbar\": \"se\",\n",
    "        # },\n",
    "        # \"smoothed\": {\n",
    "        #     \"errorbar\": \"se\",\n",
    "        # },\n",
    "} \n",
    "\n",
    "fig = plot_runs(\n",
    "    _plot_runs, \n",
    "    **_plot_kwargs,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_runs = {k: v for k, v in EXP_RUNS.items() if \"bootstrap\" in k}\n",
    "_plot_kwargs = copy.deepcopy(PLOT_KWARGS)\n",
    "_plot_kwargs[\"top_runs\"] = []\n",
    "_plot_kwargs[\"n_cols\"] = 1\n",
    "_plot_kwargs[\"metrics\"] = [\"finemath_4plus_val.nll_per_token\"]\n",
    "\n",
    "fig = plot_runs(\n",
    "    _plot_runs, \n",
    "    **_plot_kwargs,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latent-lingua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
