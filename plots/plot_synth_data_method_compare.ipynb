{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator, LogLocator\n",
    "\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runs(\n",
    "        runs, metrics=METRICS, warmstart_ckpt=None, use_token_measures=True, \n",
    "        plot_warmstart=False, plot_warmstart_horizontal_line=False, n_cols=4, unify_legend=True, legend_n_col=None, unit_figsize=None, log_x_scale=False, log_y_scale=False, \n",
    "        plot_raw_token_adjusted_x_axis=False, plot_line_kwargs=None, run_labels_map=None, display_result=False,\n",
    "        vertical_lines=None, load_metric_kwargs=None,\n",
    "    ):\n",
    "\n",
    "    additional_plot_types = [\"envelope\", \"smoothed\"]\n",
    "    if plot_line_kwargs is None:\n",
    "        plot_line_kwargs = {\n",
    "            \"average\": {  # average of all trials\n",
    "                \"errorbar\": \"se\",\n",
    "            },\n",
    "            # \"envelope\": {  # envelope of all trials\n",
    "            #     \"errorbar\": \"se\",\n",
    "            # },\n",
    "            # \"smoothed\": {  # smoothed line of all trials\n",
    "            #     \"errorbar\": \"se\",\n",
    "            # },\n",
    "        }\n",
    "    \n",
    "    # gather all metrics from all runs at all steps\n",
    "    load_runs = runs.copy()\n",
    "    if warmstart_ckpt is not None and plot_warmstart:\n",
    "        load_runs[WARMSTART_NAME] = warmstart_ckpt[\"path\"]\n",
    "        potential_paths = [warmstart_ckpt[\"path\"], warmstart_ckpt[\"path\"]+\"_trial_0\"]\n",
    "        \n",
    "        warmstart_path = None\n",
    "        for path in potential_paths:\n",
    "            if os.path.exists(os.path.join(BASE_EXP_DIR, path, \"config.yaml\")):\n",
    "                warmstart_path = os.path.join(BASE_EXP_DIR, path)\n",
    "                break\n",
    "        \n",
    "        if warmstart_path is None:\n",
    "            raise ValueError(f\"Warmstart path not found for {warmstart_ckpt['path']}\")\n",
    "            \n",
    "        with open(os.path.join(warmstart_path, \"config.yaml\"), \"r\") as f:\n",
    "            warmstart_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "        warmstart_step = warmstart_ckpt[\"step\"]\n",
    "        loaded_warmstart_ckpt = True\n",
    "    else:\n",
    "        warmstart_step = 0\n",
    "        loaded_warmstart_ckpt = False\n",
    "    \n",
    "    if loaded_warmstart_ckpt and not plot_warmstart_horizontal_line:\n",
    "        warmstart_tokens = warmstart_config[\"data\"][\"batch_size\"] * warmstart_config[\"data\"][\"seq_len\"] * warmstart_config[\"distributed\"][\"dp_shard\"] * warmstart_step\n",
    "        warmstart_synth_raw_data_ratio = SYNTHETIC_RAW_TOKEN_RATIO_MAP[\"warmstart\"]\n",
    "    else:\n",
    "        warmstart_tokens = 0\n",
    "        warmstart_synth_raw_data_ratio = 1.0\n",
    "    \n",
    "    load_metrics = list(set(metrics))\n",
    "    if load_metric_kwargs is None:\n",
    "        load_metric_kwargs = {}\n",
    "    all_metrics = load_run_metrics(load_runs, load_metrics=load_metrics, warmstart_ckpt=warmstart_ckpt, **load_metric_kwargs)\n",
    "\n",
    "    run_order = list(runs.keys())\n",
    "    warmstart_run = None\n",
    "    if plot_warmstart:\n",
    "        if not plot_warmstart_horizontal_line:\n",
    "            # shift the steps of all runs by the step of the warmstart checkpoint\n",
    "            all_metrics.loc[(all_metrics[\"run\"] != WARMSTART_NAME) & (~all_metrics[\"run\"].str.endswith(\"(scratch)\")), \"step\"] += warmstart_step\n",
    "            all_metrics.loc[(all_metrics[\"run\"] != WARMSTART_NAME) & (~all_metrics[\"run\"].str.endswith(\"(scratch)\")), \"num_tokens\"] += warmstart_tokens\n",
    "        else:\n",
    "            warmstart_run = all_metrics[all_metrics[\"run\"] == WARMSTART_NAME]\n",
    "            # remove it from all_metrics\n",
    "            all_metrics = all_metrics[all_metrics[\"run\"] != WARMSTART_NAME]\n",
    "    \n",
    "        run_order.append(WARMSTART_NAME)\n",
    "\n",
    "    # Create a grid plot, each for one metric, and different runs in one plot for comparison\n",
    "    n_metrics = len(metrics)\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "\n",
    "    # Create subplot figure\n",
    "    if unit_figsize is None:\n",
    "        unit_figsize = (6, 4)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(unit_figsize[0]*n_cols, unit_figsize[1]*n_rows))\n",
    "    axes = axes.flatten()  # Flatten to make indexing easier\n",
    "\n",
    "    if plot_raw_token_adjusted_x_axis:\n",
    "        # compute raw tokens for different methods and mixing ratios\n",
    "        all_metrics[\"mixing_ratio\"] = all_metrics[\"run\"].str.extract(r\"_mix=(\\d+\\.\\d+)\", expand=False).astype(float)\n",
    "\n",
    "        # For runs without a mix parameter, set the mixing ratio to appropriate defaults\n",
    "        mask_no_mix = all_metrics[\"mixing_ratio\"].isna()\n",
    "        mask_baseline = all_metrics[\"run\"].str.contains(\"raw\", case=False)\n",
    "        all_metrics.loc[mask_baseline & mask_no_mix, \"mixing_ratio\"] = 1.0  # baselines use all raw data\n",
    "        all_metrics.loc[~mask_baseline & mask_no_mix, \"mixing_ratio\"] = 0.0  # non-baselines without mix use all synthetic\n",
    "\n",
    "        # Use the name mapping in SYNTHETIC_RAW_TOKEN_RATIO_MAP\n",
    "        def _get_synth_raw_data_ratio(run_name):\n",
    "            if \"pretrained\" in run_name:\n",
    "                return 1.0\n",
    "            matched_keys = list(filter(lambda x: x in run_name, SYNTHETIC_RAW_TOKEN_RATIO_MAP.keys()))\n",
    "            assert len(matched_keys) > 0, f\"No matched keys found for {run_name}: {matched_keys}\"\n",
    "            if len(matched_keys) > 1:\n",
    "                print(f\"Warning: Multiple matched keys found for {run_name}: {matched_keys}, using the first one: {matched_keys[0]}\")\n",
    "            return SYNTHETIC_RAW_TOKEN_RATIO_MAP[matched_keys[0]]\n",
    "        \n",
    "        all_metrics[\"synth_raw_data_ratio\"] = all_metrics[\"run\"].apply(_get_synth_raw_data_ratio)\n",
    "        for key in [\"step\", \"num_tokens\"]:\n",
    "            if key == \"num_tokens\":\n",
    "                warmstart_baseline = warmstart_tokens\n",
    "            else:\n",
    "                warmstart_baseline = warmstart_step\n",
    "\n",
    "            # equation: raw token/step count x, mixing ratio r, final token/step count y, synthetic/raw ratio s\n",
    "            # y = x * r + x * s * (1 - r)\n",
    "            # x = y / (r + s * (1 - r))\n",
    "            # all_metrics[f\"raw_tokens_adjusted_{key}\"] = warmstart_baseline + (all_metrics[key] - warmstart_baseline) * (all_metrics[\"mixing_ratio\"] + (1 - all_metrics[\"mixing_ratio\"]) / (all_metrics[\"synth_raw_data_ratio\"]))\n",
    "            all_metrics[f\"raw_tokens_adjusted_{key}\"] = warmstart_baseline / warmstart_synth_raw_data_ratio + (all_metrics[key] - warmstart_baseline) / (all_metrics[\"mixing_ratio\"] + (1 - all_metrics[\"mixing_ratio\"]) * (all_metrics[\"synth_raw_data_ratio\"]))\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]\n",
    "        # Use seaborn's lineplot instead of matplotlib's plot\n",
    "        if use_token_measures:\n",
    "            measure = \"num_tokens\"\n",
    "        else:\n",
    "            measure = \"step\"\n",
    "\n",
    "        if plot_raw_token_adjusted_x_axis:\n",
    "            x_name = f\"raw_tokens_adjusted_{measure}\"\n",
    "        else:\n",
    "            x_name = measure\n",
    "        \n",
    "        plot_style_kwargs = {\n",
    "            \"linewidth\": 2.5,\n",
    "            \"alpha\": 0.6 if any(plot_line_type in plot_line_kwargs for plot_line_type in additional_plot_types) else 1.0,\n",
    "        }\n",
    "\n",
    "        # Plot horizontal lines for baseline runs at step 0\n",
    "        hue_order_map = {run: idx for idx, run in enumerate(run_order)}\n",
    "\n",
    "        baseline_data = all_metrics[all_metrics['step'].isna()]\n",
    "        if not baseline_data.empty:\n",
    "            x_min = all_metrics[x_name].min()\n",
    "            x_max = all_metrics[x_name].max()\n",
    "            \n",
    "            for run in baseline_data['run'].unique():\n",
    "                run_baseline = baseline_data[baseline_data['run'] == run]\n",
    "                if not run_baseline.empty:\n",
    "                    baseline_value = run_baseline[metric].iloc[0]\n",
    "                    ax.axhline(\n",
    "                        # y=baseline_value, xmin=x_min, xmax=x_max, \n",
    "                        y=baseline_value,\n",
    "                        color=\"gray\",\n",
    "                        linestyle='--', label=f\"{run}\",\n",
    "                        **plot_style_kwargs\n",
    "                    )\n",
    "\n",
    "        # Then plot the rest of the data (excluding step=0)\n",
    "        plot_data = all_metrics[all_metrics['step'].notna()]\n",
    "        hue_order_map_plot = {run: hue_order_map[run] for run in plot_data[\"run\"].unique()}\n",
    "\n",
    "        \n",
    "        if \"average\" in plot_line_kwargs:\n",
    "            sns.lineplot(\n",
    "                data=plot_data, \n",
    "                x=x_name, \n",
    "                y=metric, \n",
    "                hue=\"run\", \n",
    "                ax=ax, \n",
    "                hue_order=hue_order_map_plot, \n",
    "                marker=\"o\",\n",
    "                **plot_line_kwargs[\"average\"],\n",
    "                **plot_style_kwargs,\n",
    "            )\n",
    "        \n",
    "        for plot_line_type in additional_plot_types:\n",
    "            if plot_line_type not in plot_line_kwargs:\n",
    "                continue\n",
    "\n",
    "            # Add smoothed version using rolling average\n",
    "            color_map = {line.get_label(): line.get_color() for line in ax.get_lines()}\n",
    "        \n",
    "            extra_metrics = post_process_metrics(all_metrics, process_type=plot_line_type, metric_cols=[metric], sort_by_col=x_name)\n",
    "\n",
    "            # display(extra_metrics.head(100))\n",
    "\n",
    "            for j, run in enumerate(run_order):\n",
    "                if run in baseline_data[\"run\"].unique() or (plot_warmstart and run in warmstart_run[\"run\"].unique()):\n",
    "                    continue\n",
    "\n",
    "\n",
    "                run_data = extra_metrics[extra_metrics['run'] == run]\n",
    "\n",
    "                if display_result:\n",
    "                    # display the last step result\n",
    "                    last_step_data = run_data[run_data[x_name] == run_data[x_name].max()]\n",
    "                    display(last_step_data[[\"run\", \"step\", \"num_tokens\", metric]])\n",
    "\n",
    "                sns.lineplot(\n",
    "                    data=run_data, x=x_name, y=metric, \n",
    "                    ax=ax,\n",
    "                    color=color_map[run] if \"average\" in plot_line_kwargs else None, \n",
    "                    linewidth=3,\n",
    "                    label=None if \"average\" in plot_line_kwargs else run,\n",
    "                    **plot_line_kwargs[plot_line_type],\n",
    "                )\n",
    "\n",
    "        \n",
    "        if vertical_lines is not None:\n",
    "            assert isinstance(vertical_lines, list), \"vertical_lines must be a list\"\n",
    "            for line in vertical_lines:\n",
    "                assert isinstance(line, dict), \"vertical_lines must be a list of dictionaries\"\n",
    "                line[\"linewidth\"] = 2   \n",
    "                ax.axvline(**line)\n",
    "\n",
    "\n",
    "        if plot_warmstart and plot_warmstart_horizontal_line:\n",
    "            ax.axhline(y=warmstart_run[warmstart_run[\"step\"] == warmstart_step][metric].iloc[0], color=sns.color_palette()[hue_order_map[WARMSTART_NAME]], linestyle=\"--\", label=f\"{WARMSTART_NAME}\", linewidth=2)\n",
    "\n",
    "\n",
    "        if run_labels_map is not None:\n",
    "            # Get all lines and their labels from the plot\n",
    "            lines = ax.get_lines()\n",
    "            for line in lines:\n",
    "                current_label = line.get_label()\n",
    "                if current_label in run_labels_map:\n",
    "                    line.set_label(run_labels_map[current_label])\n",
    "        \n",
    "        if not unify_legend:\n",
    "            # Remove existing legend if any\n",
    "            if ax.get_legend() is not None:\n",
    "                ax.get_legend().remove()\n",
    "            # Create new legend with updated labels\n",
    "            ax.legend()\n",
    "            legend = ax.get_legend()\n",
    "            for handle in legend.get_lines():\n",
    "                handle.set_alpha(1.0)\n",
    "        else:\n",
    "            if ax.get_legend() is not None:\n",
    "                ax.get_legend().remove()\n",
    "\n",
    "        ax.set_ylabel(\"Metric\")\n",
    "        ax.grid(True)\n",
    "        \n",
    "\n",
    "        if log_x_scale:\n",
    "            ax.set_xscale(\"log\", base=10)\n",
    "\n",
    "        if log_y_scale:\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.grid(True, which='both', axis='y')   # add back the grid line\n",
    "        \n",
    "        if \"nll\" in metric or \"elbo\" in metric:\n",
    "            ax.set_yscale(\"log\")\n",
    "            # disable scientific notation\n",
    "            ax.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "            ax.yaxis.set_minor_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "            ax.grid(True, which='both', axis='y')   # add back the grid line\n",
    "\n",
    "            if \"nll\" in metric:\n",
    "                ax.set_ylabel(\"NLL\")\n",
    "            elif \"elbo\" in metric:\n",
    "                ax.set_ylabel(\"ELBO w/ 4 Samples\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title(ALL_EVAL_METRIC_LABEL_MAP.get(metric, metric))\n",
    "\n",
    "        if x_name == \"num_tokens\":\n",
    "            ax.set_xlabel(\"Total Training Tokens\")\n",
    "        elif x_name == \"step\":\n",
    "            ax.set_xlabel(\"Training Steps\")\n",
    "        elif x_name == \"raw_tokens_adjusted_num_tokens\":\n",
    "            ax.set_xlabel(\"Effective Raw Tokens Seen\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown x_name: {x_name}\")\n",
    "\n",
    "\n",
    "    # Remove empty subplots if any\n",
    "    for idx in range(len(metrics), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    if unify_legend:\n",
    "        # Adjust the figure size to accommodate the legend at the top\n",
    "        plt.gcf().set_size_inches(unit_figsize[0]*n_cols, unit_figsize[1]*n_rows + 1)  # Added extra height instead of width\n",
    "        # Create unified legend at the top\n",
    "        handles, labels = axes[0].get_legend_handles_labels()\n",
    "        \n",
    "        if any(plot_line_type in plot_line_kwargs for plot_line_type in additional_plot_types):\n",
    "            new_handles = []\n",
    "            for handle in handles:\n",
    "                new_handle = plt.Line2D([], [], color=handle.get_color(), label=handle.get_label(), alpha=1.0)\n",
    "                new_handles.append(new_handle)\n",
    "        else:\n",
    "            new_handles = handles\n",
    "        \n",
    "        fig.legend(new_handles, labels, bbox_to_anchor=(0.5, 1.0), loc='lower center', ncol=legend_n_col or len(run_order), fontsize=SIZE_MEDIUM)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.5)  # Adjust these values as needed\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_RUNS = {\n",
    "    # # # Method compare\n",
    "    \"latent_thought\": \"train_synth_data_method_compare_warmstart/train_synth_data_method_compare_warmstart_latent=random_opt=cosine_lr=1e-4_latent_thought\",\n",
    "    \"raw_fresh\": \"train_synth_data_method_compare_warmstart/train_synth_data_method_compare_warmstart_latent=null_opt=cosine_lr=1e-4_raw_fresh\",\n",
    "    \"raw_repeat\": \"train_synth_data_method_compare_warmstart/train_synth_data_method_compare_warmstart_latent=null_opt=cosine_lr=1e-4_raw_repeat\",\n",
    "\n",
    "    \"wrap_base\": \"train_synth_data_method_compare_warmstart/train_synth_data_method_compare_warmstart_latent=pure_opt=cosine_lr=1e-4_wrap_baseline_mix=0.0\",\n",
    "    \"wrap_cot\": \"train_synth_data_method_compare_warmstart/train_synth_data_method_compare_warmstart_latent=pure_opt=cosine_lr=1e-4_wrap_cot_mix=0.0\",\n",
    "    # \"baseline_pretrained_tinyllama\": \"pretrained_hf_ckpts/TinyLlama/TinyLlama_v1.1-embd-resized\",\n",
    "}\n",
    "\n",
    "\n",
    "RUN_LABELS_MAP = {\n",
    "    \"latent_thought\": \"Latent Thought\",\n",
    "    \"raw_fresh\": \"Raw-Fresh\",\n",
    "    \"raw_repeat\": \"Raw-Repeat\",\n",
    "    \"wrap_base\": \"WRAP-Orig\",\n",
    "    \"wrap_cot\": \"WRAP-CoT\",\n",
    "    \"surface_cot\": \"Latent Thought (Mix in Surface)\",\n",
    "    # \"baseline_pretrained_tinyllama\": \"Pretrained TinyLlama\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_METRCS = [\n",
    "    \"hendrycks_math_cot_synthetic.exact_match\", \"hendrycks_math_cot.exact_match\",\n",
    "    \"gsm8k_cot_synthetic_alt.exact_match\", \"gsm8k_cot_alt.exact_match\",\n",
    "    # \"mmlu_cot_synthetic_stem.exact_match\", \"mmlu_cot_flan_stem.exact_match\",\n",
    "]\n",
    "\n",
    "PLOT_KWARGS = {\n",
    "    \"metrics\": PLOT_METRCS,\n",
    "    \"log_x_scale\": True, \n",
    "    \"log_y_scale\": False, \n",
    "    \"legend_n_col\": 3,\n",
    "    \"plot_raw_token_adjusted_x_axis\": False,\n",
    "    \"plot_warmstart\": False,\n",
    "    \"plot_warmstart_horizontal_line\": False,\n",
    "    \"load_metric_kwargs\": {\n",
    "        \"load_all_trials\": True,\n",
    "    },\n",
    "    \"plot_line_kwargs\": {\n",
    "        \"average\": {\n",
    "            \"errorbar\": \"se\",\n",
    "        },\n",
    "        # \"envelope\": {\n",
    "        #     \"errorbar\": \"se\",\n",
    "        # },\n",
    "        # \"smoothed\": {\n",
    "        #     \"errorbar\": \"se\",\n",
    "        # },\n",
    "    },  \n",
    "    \"run_labels_map\": RUN_LABELS_MAP,\n",
    "    \"n_cols\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_runs = copy.deepcopy(EXP_RUNS)\n",
    "_plot_kwargs = copy.deepcopy(PLOT_KWARGS)\n",
    "\n",
    "fig = plot_runs(\n",
    "    _plot_runs, \n",
    "    **_plot_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison normalized by the effective raw tokens seen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_runs = copy.deepcopy(EXP_RUNS)\n",
    "_plot_kwargs = copy.deepcopy(PLOT_KWARGS)\n",
    "_plot_kwargs[\"plot_raw_token_adjusted_x_axis\"] = True\n",
    "\n",
    "fig = plot_runs(\n",
    "    _plot_runs, \n",
    "    **_plot_kwargs,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latent-lingua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
